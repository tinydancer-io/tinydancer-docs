# What is Data Availability Sampling ?

Any blockchain network has nodes which participate in the process of making decisions on the correct state of the chain i.e. consensus.

Any ideal version blockchain network would look something like this:

**Full nodes** <br/>
These are nodes which download and verify the entire blockchain.
Honest full nodes store and rebroadcast valid blocks that they download to
other full nodes, and broadcast block headers associated with valid blocks
to light clients. Some of these nodes may participate in consensus (i.e., by
producing blocks).

**Light clients** <br/>
These are nodes with computational capacity and network
bandwidth that is too low to download and verify the entire blockchain.
They receive block headers from full nodes, and on request, Merkle proofs
that some transaction or state is a part of the block header.

The core responsibility of any ideal blockchain network is to ensure that all the ledger data is always available. Also as time passes, the size of the ledger grows exponentially especially in blockchains like Solana where the number of transactions or state transitions per day are in the order of millions. Even though solana nodes store upto two days worth of data (per epoch) the size of the data can be as much as 40-50 GB. This makes it infeasible for any normal user to verify the state of their transactions on their own, which is why they rely on full-nodes like RPCs.
A light client doesn't download the entire ledger state
